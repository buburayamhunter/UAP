{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load semua data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load data yang berformat npz dan langsung ambil `value` dari key `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(\"numpy_files/images.npz\")[\"data\"]\n",
    "image_names = np.load(\"numpy_files/image_name.npz\", allow_pickle=True)[\"data\"]\n",
    "gray_feature = np.load(\"numpy_files/gray_feature.npz\")[\"data\"]\n",
    "canny_feature = np.load(\"numpy_files/canny_feature.npz\")[\"data\"]\n",
    "local_binary_pattern_feature = np.load(\"numpy_files/local_binary_pattern_feature.npz\")[\"data\"]\n",
    "cardboard_class = np.load(\"numpy_files/cardboard_class.npz\")[\"data\"]\n",
    "bbox = np.load(\"numpy_files/bbox.npz\")[\"data\"]\n",
    "segmentation = np.load(\"numpy_files/segmentation.npz\")[\"data\"]\n",
    "segmentation_category = np.load(\"numpy_files/segmentation_category.npz\")[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cek shape dari setiap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        images:                 (369, 1, 300, 400, 3)\n",
      "        images_with_bg:         (369, 1, 300, 400, 3)\n",
      "        image_names:            (369,)\n",
      "        gray_feature:           (369, 1, 300, 400)\n",
      "        canny_feature:          (369, 1, 300, 400)\n",
      "        lbp_feature:            (369, 1, 300, 400)\n",
      "        cardboard_class:        (369, 1, 2)\n",
      "        bbox:                   (369, 5, 4)\n",
      "        segmentation:           (369, 5, 300, 400)\n",
      "        segmentation_category:  (369, 5, 3)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "        images:                 {images.shape}\n",
    "        image_names:            {image_names.shape}\n",
    "        gray_feature:           {gray_feature.shape}\n",
    "        canny_feature:          {canny_feature.shape}\n",
    "        lbp_feature:            {local_binary_pattern_feature.shape}\n",
    "        cardboard_class:        {cardboard_class.shape}\n",
    "        bbox:                   {bbox.shape}\n",
    "        segmentation:           {segmentation.shape}\n",
    "        segmentation_category:  {segmentation_category.shape}\n",
    "      \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cek total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = cardboard_class.shape[0]\n",
    "total_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate list index [0, 1, 2, ...., total_data-1]\n",
    "indices = np.arange(total_data)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- proses dibawah ini akan menghasilkan index yang akan di split\n",
    "  - misal raw_index [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "  - setelah di split akan menjadi\n",
    "    - train = [2, 4, 5, 7, 8]\n",
    "    - test = [1, 3, 10]\n",
    "    - validation = [6, 9]\n",
    "  - setelah mendapatkan index untuk setiap subset, data citra dll akan di split berdasarkan index itu tadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dengan perbandingan 80:20 untuk data train dan (test, validation)\n",
    "(train_indices, temp_indices, train_label, temp_label) = train_test_split(\n",
    "    indices,\n",
    "    cardboard_class.argmax(axis=2),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=cardboard_class.argmax(axis=2),\n",
    ")\n",
    "\n",
    "# split 20% tadi menjadi 2 (50:50) untuk data test dan validation\n",
    "(val_indices, test_indices, val_label, test_label) = train_test_split(\n",
    "    temp_indices, temp_label, test_size=0.5, random_state=42, stratify=temp_label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- buat fungsi untuk menerapkan hasil split index ke data aslinya untuk setiap subset nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(data, train_indices, test_indices, val_indices):\n",
    "    train_data = data[train_indices]\n",
    "    test_data = data[test_indices]\n",
    "    val_data = data[val_indices]\n",
    "\n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split semua data yang diawal tadi dengan hasil split index `train`, `test`, `val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, val_images = train_test_val_split(\n",
    "    images, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_image_names, test_image_names, val_image_names = train_test_val_split(\n",
    "    image_names, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_gray_feature, test_gray_feature, val_gray_feature = train_test_val_split(\n",
    "    gray_feature, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_canny_feature, test_canny_feature, val_canny_feature = train_test_val_split(\n",
    "    canny_feature, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "(\n",
    "    train_local_binary_pattern_feature,\n",
    "    test_local_binary_pattern_feature,\n",
    "    val_local_binary_pattern_feature,\n",
    ") = train_test_val_split(\n",
    "    local_binary_pattern_feature, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_cardboard_class, test_cardboard_class, val_cardboard_class = train_test_val_split(\n",
    "    cardboard_class, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_bbox, test_bbox, val_bbox = train_test_val_split(\n",
    "    bbox, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_segmentation, test_segmentation, val_segmentation = train_test_val_split(\n",
    "    segmentation, train_indices, test_indices, val_indices\n",
    ")\n",
    "\n",
    "train_segmentation_category, test_segmentation_category, val_segmentation_category = (\n",
    "    train_test_val_split(\n",
    "        segmentation_category, train_indices, test_indices, val_indices\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tampilkan hasil split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data : 295 data\n",
      "test_data : 37 data\n",
      "val_data : 37 data\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data :\", train_images.shape[0], \"data\")\n",
    "print(\"test_data :\", test_images.shape[0], \"data\")\n",
    "print(\"val_data :\", val_images.shape[0], \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tampilkan distribusi setelah proses split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi Split Data\n",
      "Train Data:\n",
      "\n",
      "    Normal : 144 data\n",
      "    Defect : 151 data\n",
      "\n",
      "    \n",
      "Test Data:\n",
      "\n",
      "    Normal : 18 data\n",
      "    Defect : 19 data\n",
      "\n",
      "    \n",
      "Validation Data:\n",
      "\n",
      "    Normal : 18 data\n",
      "    Defect : 19 data\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# ambil banyak data setiap kelas di setiap subset\n",
    "train_normal = len(train_label[train_label == [0]])\n",
    "train_defect = len(train_label[train_label == [1]])\n",
    "test_normal = len(test_label[test_label == [0]])\n",
    "test_defect = len(test_label[test_label == [1]])\n",
    "val_normal = len(val_label[val_label == [0]])\n",
    "val_defect = len(val_label[val_label == [1]])\n",
    "\n",
    "print(\"Distribusi Split Data\")\n",
    "\n",
    "print(\n",
    "    f\"\"\"Train Data:\n",
    "\n",
    "    Normal : {train_normal} data\n",
    "    Defect : {train_defect} data\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "print(\n",
    "    f\"\"\"Test Data:\n",
    "\n",
    "    Normal : {test_normal} data\n",
    "    Defect : {test_defect} data\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "print(\n",
    "    f\"\"\"Validation Data:\n",
    "\n",
    "    Normal : {val_normal} data\n",
    "    Defect : {val_defect} data\n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan hasil split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fungsi untuk mengekspor citra setelah proses split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf images-split-data\n",
    "\n",
    "def export_split_data_to_image(\n",
    "    image,\n",
    "    image_name,\n",
    "    label,\n",
    "    feature,\n",
    "    train_indices,\n",
    "    test_indices,\n",
    "    val_indices,\n",
    "    export_path=\"images-split-data\",\n",
    "):\n",
    "    # ubah label kelas ke bentuk flatten\n",
    "    label = label[:,0].argmax(axis=1)\n",
    "    \n",
    "    # convert label kelas ke string (bentuk awalnya adalah one hot encoder)\n",
    "    label = np.where(label == 0, \"normal\", \"defect\")\n",
    "\n",
    "    for subset, indices in zip([\"train\", \"test\", \"val\"],[train_indices, test_indices, val_indices]):\n",
    "        for i in indices:\n",
    "            \n",
    "            # buat direktori untuk menyimpan citra hasil split data\n",
    "            os.makedirs(os.path.join(export_path, feature, subset, label[i]), exist_ok=True)\n",
    "            path = os.path.join(export_path, feature, subset, label[i], image_name[i])\n",
    "            if image[i][0].ndim == 3:\n",
    "                \n",
    "                # convert citra menjadi channel BGR, karena opencv saat melakukan imwrite akan mengubah ke RGB lagi\n",
    "                # jika citra memiliki channel RGB maka saat opencv melakukan imwrite akan disimpan dengan channel BGR\n",
    "                image[i][0] = cv2.cvtColor(image[i][0], cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # simpan citra ke path yang telah diberikan\n",
    "            if np.max(image[i][0]) > 1:\n",
    "                cv2.imwrite(path, image[i][0])\n",
    "            else:\n",
    "                cv2.imwrite(path, (image[i][0]*255).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- terapkan fungsi diatas untuk menyimpan citra hasil split setiap fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_split_data_to_image(\n",
    "    images,\n",
    "    image_names,\n",
    "    cardboard_class,\n",
    "    \"original\",\n",
    "    train_indices,\n",
    "    test_indices,\n",
    "    val_indices,\n",
    ")\n",
    "export_split_data_to_image(\n",
    "    gray_feature,\n",
    "    image_names,\n",
    "    cardboard_class,\n",
    "    \"gray\",\n",
    "    train_indices,\n",
    "    test_indices,\n",
    "    val_indices,\n",
    ")\n",
    "export_split_data_to_image(\n",
    "    canny_feature,\n",
    "    image_names,\n",
    "    cardboard_class,\n",
    "    \"canny\",\n",
    "    train_indices,\n",
    "    test_indices,\n",
    "    val_indices,\n",
    ")\n",
    "export_split_data_to_image(\n",
    "    local_binary_pattern_feature,\n",
    "    image_names,\n",
    "    cardboard_class,\n",
    "    \"lbp\",\n",
    "    train_indices,\n",
    "    test_indices,\n",
    "    val_indices,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simpan semua dataset hasil split data ke dalam format npz\n",
    "- akan memiliki struktur key:value\n",
    "- memiliki key `train`, `test`, `val` untuk mengakses data setiap subsetnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat direktori untuk menyimpan hasil split data\n",
    "os.makedirs(\"numpy_files/split_data\", exist_ok=True)\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_images.npz\",\n",
    "    train=train_images,\n",
    "    test=test_images,\n",
    "    val=val_images,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_image_name.npz\",\n",
    "    train=train_image_names,\n",
    "    test=test_image_names,\n",
    "    val=val_image_names,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_gray_feature.npz\",\n",
    "    train=train_gray_feature,\n",
    "    test=test_gray_feature,\n",
    "    val=val_gray_feature,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_canny_feature.npz\",\n",
    "    train=train_canny_feature,\n",
    "    test=test_canny_feature,\n",
    "    val=val_canny_feature,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_local_binary_pattern_feature.npz\",\n",
    "    train=train_local_binary_pattern_feature,\n",
    "    test=test_local_binary_pattern_feature,\n",
    "    val=val_local_binary_pattern_feature,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_cardboard_class.npz\",\n",
    "    train=train_cardboard_class,\n",
    "    test=test_cardboard_class,\n",
    "    val=val_cardboard_class,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_bbox.npz\",\n",
    "    train=train_bbox,\n",
    "    test=test_bbox,\n",
    "    val=val_bbox,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_segmentation.npz\",\n",
    "    train=train_segmentation,\n",
    "    test=test_segmentation,\n",
    "    val=val_segmentation,\n",
    ")\n",
    "np.savez_compressed(\n",
    "    \"numpy_files/split_data/split_segmentation_category.npz\",\n",
    "    train=train_segmentation_category,\n",
    "    test=test_segmentation_category,\n",
    "    val=val_segmentation_category,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
